#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸»ç¨‹åº / Main Program
ä¾æ¬¡æ‰§è¡Œå››ä¸ªå­æ¨¡å—çš„æ•°æ®çˆ¬å–è„šæœ¬ï¼Œå¹¶å°†ç»“æœåˆå¹¶åˆ°ä¸€ä¸ªExcelæ–‡ä»¶ä¸­
Execute four sub-module data scraping scripts sequentially and merge results into one Excel file

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-07-01
"""

import os
import sys
import subprocess
import pandas as pd
import openpyxl
from datetime import datetime
import logging
from pathlib import Path
import traceback

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('main_execution.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DataIntegrator:
    """æ•°æ®æ•´åˆå™¨ç±» / Data Integrator Class"""
    
    def __init__(self, output_filename="integrated_data.xlsx"):
        self.output_filename = output_filename
        self.scripts_config = [
            {
                'name': 'Commodity Price Crawler',
                'name_cn': 'å•†å“ä»·æ ¼çˆ¬è™«',
                'script_path': 'func1/commodity_price_crawler.py',
                'output_files': ['func1/rubber_prices.txt'],
                'sheet_name': 'Rubber_TSR20'
            },
            {
                'name': 'BLS Data Scraper',
                'name_cn': 'BLSæ•°æ®çˆ¬è™«',
                'script_path': 'func2/bls_scraper_auto.py',
                'output_files': ['func2/output/combined_data.xlsx', 'func2/bls_data.xlsx'],
                'sheet_name': 'Commodity_Data'
            },
            {
                'name': 'Exchange Rate Scraper',
                'name_cn': 'æ±‡ç‡æ•°æ®çˆ¬è™«',
                'script_path': 'func3/exchange_rate_scraper.py',
                'output_files': ['func3/exchange_rates.xlsx', 'func3/exchange_rates.txt'],
                'sheet_name': 'Exchange_Rates'
            },
            {
                'name': 'FRED Data Scraper',
                'name_cn': 'FREDæ•°æ®çˆ¬è™«',
                'script_path': 'func4/run.py',
                'output_files': ['func4/output/PCU314994314994_processed.xlsx', 'func4/output/PCU314994314994.xlsx'],
                'sheet_name': 'Commodity_Data'
            }
        ]
        
    def execute_script(self, script_path):
        """
        æ‰§è¡Œå•ä¸ªè„šæœ¬ / Execute single script
        
        Args:
            script_path (str): è„šæœ¬è·¯å¾„
            
        Returns:
            bool: æ‰§è¡ŒæˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
        """
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œè„šæœ¬ / Starting script: {script_path}")
            
            # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
            script_dir = os.path.dirname(script_path)
            script_name = os.path.basename(script_path)
            
            # åˆ‡æ¢åˆ°è„šæœ¬ç›®å½•æ‰§è¡Œ
            original_cwd = os.getcwd()
            if script_dir:
                os.chdir(script_dir)
                logger.info(f"åˆ‡æ¢åˆ°ç›®å½• / Changed to directory: {script_dir}")
            
            # æ‰§è¡Œè„šæœ¬
            result = subprocess.run(
                [sys.executable, script_name],
                capture_output=True,
                text=True,
                timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
            )
            
            # åˆ‡æ¢å›åŸç›®å½•
            os.chdir(original_cwd)
            
            if result.returncode == 0:
                logger.info(f"è„šæœ¬æ‰§è¡ŒæˆåŠŸ / Script executed successfully: {script_path}")
                if result.stdout:
                    logger.info(f"è¾“å‡º / Output:\n{result.stdout}")
                return True
            else:
                logger.error(f"è„šæœ¬æ‰§è¡Œå¤±è´¥ / Script execution failed: {script_path}")
                logger.error(f"é”™è¯¯ç  / Return code: {result.returncode}")
                if result.stderr:
                    logger.error(f"é”™è¯¯ä¿¡æ¯ / Error output:\n{result.stderr}")
                if result.stdout:
                    logger.error(f"æ ‡å‡†è¾“å‡º / Standard output:\n{result.stdout}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error(f"è„šæœ¬æ‰§è¡Œè¶…æ—¶ / Script execution timeout: {script_path}")
            return False
        except Exception as e:
            logger.error(f"æ‰§è¡Œè„šæœ¬æ—¶å‘ç”Ÿå¼‚å¸¸ / Exception during script execution: {script_path}")
            logger.error(f"å¼‚å¸¸ä¿¡æ¯ / Exception details: {str(e)}")
            logger.error(f"å †æ ˆè·Ÿè¸ª / Stack trace:\n{traceback.format_exc()}")
            return False
        finally:
            # ç¡®ä¿å›åˆ°åŸç›®å½•
            try:
                os.chdir(original_cwd)
            except:
                pass
    
    def read_txt_data(self, file_path):
        """
        è¯»å–æ–‡æœ¬æ–‡ä»¶æ•°æ® / Read text file data
        
        Args:
            file_path (str): æ–‡ä»¶è·¯å¾„
            
        Returns:
            pd.DataFrame: æ•°æ®æ¡†
        """
        try:
            data = []
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        if ':' in line:
                            parts = line.split(':', 1)
                            if len(parts) == 2:
                                date_str = parts[0].strip()
                                value_str = parts[1].strip()
                                # æå–æ•°å€¼ï¼ˆå»æ‰å•ä½ï¼‰
                                try:
                                    value = float(value_str.split()[0])
                                    data.append({'Date': date_str, 'Value': value})
                                except:
                                    pass
            
            return pd.DataFrame(data)
            
        except Exception as e:
            logger.error(f"è¯»å–æ–‡æœ¬æ–‡ä»¶å¤±è´¥ / Failed to read text file {file_path}: {e}")
            return pd.DataFrame()
    
    def read_excel_data(self, file_path, sheet_name=None):
        """
        è¯»å–Excelæ–‡ä»¶æ•°æ® / Read Excel file data
        
        Args:
            file_path (str): æ–‡ä»¶è·¯å¾„
            sheet_name (str): å·¥ä½œè¡¨åç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            pd.DataFrame: æ•°æ®æ¡†
        """
        try:
            if sheet_name:
                df = pd.read_excel(file_path, sheet_name=sheet_name)
            else:
                df = pd.read_excel(file_path)
            
            logger.info(f"æˆåŠŸè¯»å–Excelæ–‡ä»¶ / Successfully read Excel file: {file_path}")
            logger.info(f"æ•°æ®å½¢çŠ¶ / Data shape: {df.shape}")
            return df
            
        except Exception as e:
            logger.error(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥ / Failed to read Excel file {file_path}: {e}")
            return pd.DataFrame()
    
    def process_output_files(self, config):
        """
        å¤„ç†è¾“å‡ºæ–‡ä»¶ / Process output files
        
        Args:
            config (dict): è„šæœ¬é…ç½®
            
        Returns:
            pd.DataFrame: å¤„ç†åçš„æ•°æ®æ¡†
        """
        output_files = config['output_files']
        combined_data = pd.DataFrame()
        
        for file_path in output_files:
            if not os.path.exists(file_path):
                logger.warning(f"è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨ / Output file does not exist: {file_path}")
                continue
                
            try:
                if file_path.endswith('.txt'):
                    df = self.read_txt_data(file_path)
                elif file_path.endswith(('.xlsx', '.xls')):
                    df = self.read_excel_data(file_path)
                else:
                    logger.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ / Unsupported file format: {file_path}")
                    continue
                
                if not df.empty:
                    # æ·»åŠ æ•°æ®æºä¿¡æ¯
                    df['Source_File'] = os.path.basename(file_path)
                    df['Data_Source'] = config['name']
                    df['Generated_At'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    
                    if combined_data.empty:
                        combined_data = df
                    else:
                        combined_data = pd.concat([combined_data, df], ignore_index=True)
                
            except Exception as e:
                logger.error(f"å¤„ç†è¾“å‡ºæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ / Error processing output file {file_path}: {e}")
        
        return combined_data
    
    def create_integrated_excel(self, all_data):
        """
        åˆ›å»ºæ•´åˆçš„Excelæ–‡ä»¶ / Create integrated Excel file
        
        Args:
            all_data (dict): æ‰€æœ‰æ•°æ®å­—å…¸
        """
        try:
            with pd.ExcelWriter(self.output_filename, engine='openpyxl') as writer:
                # åˆ›å»ºæ±‡æ€»sheet
                summary_data = []
                for config in self.scripts_config:
                    sheet_name = config['sheet_name']
                    data = all_data.get(sheet_name, pd.DataFrame())
                    
                    # æ·»åŠ æ•°æ®æ¥æºç½‘ç«™
                    data_source_url = {
                        'Commodity Price Crawler': 'https://www.worldbank.org/en/research/commodity-markets',
                        'BLS Data Scraper': 'https://data.bls.gov/toppicks?survey=pc',
                        'Exchange Rate Scraper': 'https://www.x-rates.com/average/',
                        'FRED Data Scraper': 'https://fred.stlouisfed.org/series/PCU314994314994'
                    }
                    
                    summary_data.append({
                        'Module': config['name'],
                        'Module_CN': config['name_cn'],
                        'Sheet_Name': sheet_name,
                        'Records_Count': len(data),
                        'Status': 'Success' if not data.empty else 'No Data',
                        'Source_URL': data_source_url.get(config['name'], ''),
                        'Generated_At': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    })
                
                summary_df = pd.DataFrame(summary_data)
                summary_df.to_excel(writer, sheet_name='Summary', index=False)
                logger.info("åˆ›å»ºæ±‡æ€»å·¥ä½œè¡¨ / Created summary worksheet")
                
                # å†™å…¥å„ä¸ªæ¨¡å—çš„æ•°æ®ï¼ˆåªä¸ºæ¯ä¸ªå”¯ä¸€çš„sheet_nameåˆ›å»ºä¸€ä¸ªå·¥ä½œè¡¨ï¼‰
                processed_sheets = set()
                for config in self.scripts_config:
                    sheet_name = config['sheet_name']
                    
                    # è·³è¿‡å·²ç»å¤„ç†è¿‡çš„sheet
                    if sheet_name in processed_sheets:
                        continue
                    
                    processed_sheets.add(sheet_name)
                    data = all_data.get(sheet_name, pd.DataFrame())
                    
                    if not data.empty:
                        data.to_excel(writer, sheet_name=sheet_name, index=False)
                        logger.info(f"å†™å…¥æ•°æ®åˆ°å·¥ä½œè¡¨ / Wrote data to worksheet: {sheet_name} ({len(data)} è¡Œè®°å½• / records)")
                    else:
                        # åˆ›å»ºç©ºçš„å·¥ä½œè¡¨å¹¶æ·»åŠ è¯´æ˜
                        empty_df = pd.DataFrame({
                            'Status': ['No data available'],
                            'Message': [f'No output data found for sheet: {sheet_name}'],
                            'Generated_At': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')]
                        })
                        empty_df.to_excel(writer, sheet_name=sheet_name, index=False)
                        logger.warning(f"åˆ›å»ºç©ºå·¥ä½œè¡¨ / Created empty worksheet: {sheet_name}")
                
                # Metadataå·¥ä½œè¡¨å·²ç§»é™¤ï¼Œæ ¹æ®ç”¨æˆ·éœ€æ±‚
            
            logger.info(f"æ•´åˆExcelæ–‡ä»¶åˆ›å»ºæˆåŠŸ / Integrated Excel file created successfully: {self.output_filename}")
            
        except Exception as e:
            logger.error(f"åˆ›å»ºæ•´åˆExcelæ–‡ä»¶å¤±è´¥ / Failed to create integrated Excel file: {e}")
            raise
    
    def run(self):
        """
        è¿è¡Œä¸»ç¨‹åº / Run main program
        """
        logger.info("=" * 80)
        logger.info("ğŸš€ æ•°æ®æ•´åˆç¨‹åºå¯åŠ¨ / Data Integration Program Started")
        logger.info("=" * 80)
        
        start_time = datetime.now()
        all_data = {}
        execution_results = {}
        
        try:
            # ä¾æ¬¡æ‰§è¡Œå„ä¸ªè„šæœ¬
            for i, config in enumerate(self.scripts_config, 1):
                logger.info(f"\nğŸ“Š [{i}/{len(self.scripts_config)}] æ‰§è¡Œæ¨¡å— / Executing module: {config['name']} ({config['name_cn']})")
                logger.info(f"ğŸ“ è„šæœ¬è·¯å¾„ / Script path: {config['script_path']}")
                
                # æ‰§è¡Œè„šæœ¬
                success = self.execute_script(config['script_path'])
                execution_results[config['name']] = success
                
                if success:
                    logger.info(f"âœ… æ¨¡å—æ‰§è¡ŒæˆåŠŸ / Module executed successfully: {config['name']}")
                    
                    # å¤„ç†è¾“å‡ºæ–‡ä»¶
                    logger.info("ğŸ“¤ å¤„ç†è¾“å‡ºæ–‡ä»¶ / Processing output files...")
                    data = self.process_output_files(config)
                    
                    # å¦‚æœsheet_nameå·²å­˜åœ¨ï¼Œåˆå¹¶æ•°æ®ï¼›å¦åˆ™åˆ›å»ºæ–°çš„
                    if config['sheet_name'] in all_data:
                        if not data.empty and not all_data[config['sheet_name']].empty:
                            all_data[config['sheet_name']] = pd.concat([all_data[config['sheet_name']], data], ignore_index=True)
                            logger.info(f"ğŸ“ˆ åˆå¹¶æ•°æ®åˆ°ç°æœ‰å·¥ä½œè¡¨ / Merged data to existing sheet: {config['sheet_name']}")
                        elif not data.empty:
                            all_data[config['sheet_name']] = data
                    else:
                        all_data[config['sheet_name']] = data
                    
                    if not data.empty:
                        logger.info(f"ğŸ“ˆ è·å–åˆ° {len(data)} æ¡æ•°æ®è®°å½• / Retrieved {len(data)} data records")
                    else:
                        logger.warning("âš ï¸  æœªè·å–åˆ°æœ‰æ•ˆæ•°æ® / No valid data retrieved")
                else:
                    logger.error(f"âŒ æ¨¡å—æ‰§è¡Œå¤±è´¥ / Module execution failed: {config['name']}")
                    if config['sheet_name'] not in all_data:
                        all_data[config['sheet_name']] = pd.DataFrame()
                
                logger.info(f"{'='*50}")
            
            # åˆ›å»ºæ•´åˆçš„Excelæ–‡ä»¶
            logger.info("\nğŸ“‹ åˆ›å»ºæ•´åˆExcelæ–‡ä»¶ / Creating integrated Excel file...")
            self.create_integrated_excel(all_data)
            
            # æ‰§è¡Œæ±‡æ€»
            end_time = datetime.now()
            duration = end_time - start_time
            
            logger.info("\n" + "=" * 80)
            logger.info("ğŸ‰ æ•°æ®æ•´åˆç¨‹åºå®Œæˆ / Data Integration Program Completed")
            logger.info("=" * 80)
            logger.info(f"â±ï¸  æ€»è€—æ—¶ / Total duration: {duration}")
            logger.info(f"ğŸ“ è¾“å‡ºæ–‡ä»¶ / Output file: {self.output_filename}")
            
            # æ‰§è¡Œç»“æœæ±‡æ€»
            success_count = sum(1 for result in execution_results.values() if result)
            total_count = len(execution_results)
            
            logger.info(f"ğŸ“Š æ‰§è¡Œç»“æœ / Execution results: {success_count}/{total_count} æˆåŠŸ / successful")
            
            for name, result in execution_results.items():
                status = "âœ… æˆåŠŸ / Success" if result else "âŒ å¤±è´¥ / Failed"
                logger.info(f"   {name}: {status}")
            
            if success_count == total_count:
                logger.info("ğŸŠ æ‰€æœ‰æ¨¡å—æ‰§è¡ŒæˆåŠŸï¼/ All modules executed successfully!")
            elif success_count > 0:
                logger.warning(f"âš ï¸  éƒ¨åˆ†æ¨¡å—æ‰§è¡ŒæˆåŠŸ / Partial success: {success_count}/{total_count}")
            else:
                logger.error("ğŸ’¥ æ‰€æœ‰æ¨¡å—æ‰§è¡Œå¤±è´¥ / All modules failed")
            
            logger.info("=" * 80)
            
        except Exception as e:
            logger.error(f"âŒ ç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯ / Critical error during program execution: {e}")
            logger.error(f"å †æ ˆè·Ÿè¸ª / Stack trace:\n{traceback.format_exc()}")
            raise

def main():
    """ä¸»å‡½æ•° / Main function"""
    try:
        print("ğŸ”§ æ•°æ®æ•´åˆç³»ç»Ÿ / Data Integration System")
        print("=" * 60)
        print("ä¾æ¬¡æ‰§è¡Œå››ä¸ªæ•°æ®çˆ¬è™«æ¨¡å—å¹¶æ•´åˆç»“æœ")
        print("Execute four data scraping modules sequentially and integrate results")
        print("=" * 60)
        
        # åˆ›å»ºæ•°æ®æ•´åˆå™¨å¹¶è¿è¡Œ
        integrator = DataIntegrator()
        integrator.run()
        
        print(f"\nâœ… ç¨‹åºæ‰§è¡Œå®Œæˆï¼è¯·æŸ¥çœ‹è¾“å‡ºæ–‡ä»¶: {integrator.output_filename}")
        print(f"âœ… Program completed! Please check output file: {integrator.output_filename}")
        
        return 0
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ / User interrupted execution")
        return 1
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥ / Program execution failed: {e}")
        return 1

if __name__ == "__main__":
    exit(main()) 